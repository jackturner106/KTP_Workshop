{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0e92b5d",
   "metadata": {},
   "source": [
    "# MCP\n",
    "\n",
    "## What is MCP?\n",
    "Model Context Protocol (MCP) is a framework that standardizes interaction between LLMs and external tools.\n",
    "\n",
    "## Why should I use MCP?\n",
    "Allows you to define custom tooling that can be called by LLMs\n",
    "\n",
    "## Libraries for LLMs\n",
    "LLM developers generally provide libraries along with their APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b7350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if you don't have the OpenAI library installed\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8a600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "with open(\"api_keys.json\") as f:\n",
    "    keys = json.load(f)\n",
    "\n",
    "client = OpenAI(api_key=keys[\"openai\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b24bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Explain the concept of recursion in simple terms.\",\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-5-nano\",\n",
    "    )\n",
    "\n",
    "    print(chat_completion.choices[0].message.content)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2cce78",
   "metadata": {},
   "source": [
    "## Options for calling models\n",
    "\n",
    "We can make the models more helpful in a few different ways. The most basic is the system prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7b014c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": \"You are a computer science professor, helping a student with a homework assignment.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Explain the concept of recursion in simple terms.\",\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-5-nano\",\n",
    "    )\n",
    "\n",
    "    print(chat_completion.choices[0].message.content)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6813c6fe",
   "metadata": {},
   "source": [
    "## We can make the model more interactive by adapting the system and/or user prompts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8316aec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def clothing_advice(age: int, city: str, weather: str):\n",
    "    global client\n",
    "    try:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": f\"You are a friendly weather reporter, advising people on what to wear for the day. You are talking to {age} year old user in {city}, where the current weather is {weather}\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": \"What should I wear today?\"\n",
    "                }\n",
    "            ],\n",
    "            model=\"gpt-5-nano\",\n",
    "        )\n",
    "\n",
    "        print(chat_completion.choices[0].message.content)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred {e}\")\n",
    "\n",
    "clothing_advice(21, \"Boston\", \"chilly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b35198",
   "metadata": {},
   "source": [
    "## One last thing\n",
    "We can insert our own assistant prompts - essentially faking a conversation between a user and an LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5965182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clothing_advice_again(age: int, city: str, weather: str):\n",
    "    global client\n",
    "    try:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": f\"You are a friendly weather reporter, advising people on what to wear for the day. You are talking to {age} year old user in {city}, where the current weather is {weather}\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \"content\": \"What should I wear today?\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\", \"content\": \"You should wear a jacket.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \"content\": \"But I don't like jackets, suggest another idea.\"\n",
    "                }\n",
    "            ],\n",
    "            model=\"gpt-5-nano\",\n",
    "        )\n",
    "\n",
    "        print(chat_completion.choices[0].message.content)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred {e}\")\n",
    "\n",
    "clothing_advice_again(21, \"Boston\", \"chilly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fadde2b",
   "metadata": {},
   "source": [
    "## Resources\n",
    " - List of MCPClient libraries: https://github.com/punkpeye/awesome-mcp-clients\n",
    " - Python Requests API: https://requests.readthedocs.io/en/latest/\n",
    " - MCP Documentation: https://github.com/modelcontextprotocol"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
